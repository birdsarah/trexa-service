import os
import re
from time import strftime

from tqdm import trange
from tqdm import tqdm
import requests
import zipfile

from trexa import app

ALEXA_MILLION_URI = 'http://s3.amazonaws.com/alexa-static/top-1m.csv.zip'
TRANCO_100K_URI = 'https://tranco-list.eu/latest_list?provider=all&list_size=100000'  # noqa
ZIP_DOWNLOADS_DEST = app.config['ZIP_DOWNLOADS_DEST']
CSV_DOWNLOADS_DEST = app.config['CSV_DOWNLOADS_DEST']
FINAL_LIST_DEST = app.config['FINAL_LIST_DEST']

for dest in [ZIP_DOWNLOADS_DEST, CSV_DOWNLOADS_DEST, FINAL_LIST_DEST]:
    if not os.path.exists(dest):
        os.makedirs(dest)


def get_alexa():
    """Download the latest Alexa 1 Million list

    This will give it a dated name, unzip it, and trim the file to 100k,
    moving it to our CSV downloads folder.
    """
    print('Downloading the Alexa List...')
    r = requests.get(ALEXA_MILLION_URI, stream=True)
    total_size = int(r.headers.get('content-length', 0))
    t = tqdm(total=total_size, unit='iB', unit_scale=True)
    today = strftime('%Y-%m-%d')
    todays_csv = f'{CSV_DOWNLOADS_DEST}/alexa-1m-{today}.csv'

    # download the file from Amazon
    with open(f'{ZIP_DOWNLOADS_DEST}/alexa-1m-{today}.zip', 'wb') as fd:
        for chunk in r.iter_content(chunk_size=1024):
            if chunk:
                t.update(len(chunk))
                fd.write(chunk)
    # extract the file and move it to our CSV folder
    with zipfile.ZipFile(f'{ZIP_DOWNLOADS_DEST}/alexa-1m-{today}.zip') as zp:
        list = zp.infolist()[0]
        list.filename = todays_csv
        zp.extract(list)
        trim_alexa(todays_csv)
    # return the name of the file, so it can be passed to build_trexa
    return todays_csv


def trim_alexa(csv_file, number=100000, day=strftime('%Y-%m-%d')):
    """Trim the Alexa 1 Million list to have N lines

    By default N is 100000 (represented by `number`).
    """
    with open(csv_file, 'r') as csv:
        head = [next(csv) for x in range(number)]
    with open(f'{CSV_DOWNLOADS_DEST}/alexa-100k-{day}.csv', 'w') as fd:
        fd.write(''.join(head))


def get_tranco():
    """Download the latest Traco list."""
    print('Downloading the Tranco List...')
    headers = {'user-agent': 'mozilla-trexa-service'}
    today = strftime('%Y-%m-%d')
    todays_csv = f'{CSV_DOWNLOADS_DEST}/tranco-100k-{today}.csv'
    r = requests.get(TRANCO_100K_URI, headers)
    # We expect a 30X redirect to the list URL that looks like:
    # https://tranco-list.eu/list/VK9N/100000
    list_url = r.url
    # the download URL looks like:
    # https://tranco-list.eu/download/VK9N/100000
    list_url = list_url.replace('/list/', '/download/')
    dl = requests.get(list_url, headers, stream=True)
    # Tranco doesn't seem to set a dynamic content-length for these lists
    # ¯\_(ツ)_/¯. Maybe they will one day.
    total_size = int(dl.headers.get('content-length', 0))
    t = tqdm(total=total_size, unit='iB', unit_scale=True)
    with open(todays_csv, 'wb') as fd:
        for chunk in dl.iter_content(chunk_size=1024):
            if chunk:
                t.update(len(chunk))
                fd.write(chunk)
    # return the name of the file, so it can be passed to build_trexa
    return todays_csv


def read_list_csv(csv_file):
    """Read in a top site list formatted as <n>,<tld> (no headers)."""
    list_entries = []
    with open(csv_file, "rb") as f:
        for line in f:
            tld = str(line, "UTF-8").rstrip().split(",")[1]
            list_entries.append(tld)
    return list_entries


def write_list_file(tld_list, list_file):
    """Write a top site list to file.

    Writes one entry per line with no index.
    """
    with open(list_file, "w") as f:
        for n, tld in enumerate(tld_list):
            f.write(f'{n + 1},{tld}\n')


def build_trexa(alexa_list, tranco_list, list_size=100000):
    """Create the trexa list from the tranco and alexa lists.

    This is adapted from
    https://github.com/mozilla/trexa/blob/master/list_merge.py
    """
    print('Building the Trexa List...')
    # Holder for the combined list
    final_list = []
    today = strftime('%Y-%m-%d')

    # Open and parse the ALEXA TLD list from local csv.
    a = read_list_csv(alexa_list)
    # Truncate ALEXA list to minimum necessary elements to process.
    a = a[0:list_size]
    # Save the ALEXA list into a set type for sanity checking list
    # combination operations.
    alexa_set = set(a)
    alexa_subset_length = len(a)

    # Open and parse the TRANCO TLD list from local csv.
    t = read_list_csv(tranco_list)
    # Truncate TRANCO list to minimum necessary elements to process.
    t = t[0:list_size]
    # Save the TRANCO list into a set type for sanity checking list
    # combination operations.
    tranco_set = set(t)
    tranco_subset_length = len(t)

    # The combined list is generated by taking the union of top elements from
    # both lists. The rank in the final list is the minimum rank at which the
    # TLD appeared in either list, with ties broken in favour of Alexa.
    for i in trange(len(a)):
        # Guarantee that the ALEXA list is completely represented in the final
        # list.
        current_alexa_element = a.pop(0)
        # Guarantees complete coverage of ALEXA list even if this element was
        # added from earlier position in TRANCO list.
        if current_alexa_element not in final_list:
            final_list.append(current_alexa_element)

        # Check if the corresponding index in TRANCO is already in the list.
        current_tranco_element = t.pop(0)
        if current_tranco_element not in final_list:
            # If not, add the tranco list element.
            final_list.append(current_tranco_element)

    final_list_set = set(final_list)
    print("Length of combined ALEXA/TRANCO list: " + str(len(final_list)))

    set_validation = len(final_list) == len(final_list_set)
    print(
        'Verifying that the list is composed of only unique elements: {0}'.
        format(
            str(set_validation))
    )

    alexa_in_final = alexa_set.issubset(final_list_set)
    print("""The ALEXA list, truncated at {0} elements, is a complete subset
        of the final list of {1} elements: {2}""".format(
        str(alexa_subset_length), str(len(final_list)), str(alexa_in_final))
    )

    tranco_in_final = tranco_set.issubset(final_list_set)
    print(
        """The TRANCO list, truncated at {0} elements, is a complete subset
        of the final list of {1} elements: {2}""".format(
            str(tranco_subset_length), str(len(final_list)),
            str(tranco_in_final))
    )

    write_list_file(final_list, f'{FINAL_LIST_DEST}/trexa-{today}.csv')


def clean_up():
    """Remove the files that we don't need to keep around."""
    # delete all the csvs
    for csv in os.listdir(CSV_DOWNLOADS_DEST):
        os.remove(os.path.join(CSV_DOWNLOADS_DEST, csv))
    # delete all the zips
    for zip in os.listdir(ZIP_DOWNLOADS_DEST):
        os.remove(os.path.join(ZIP_DOWNLOADS_DEST, zip))
